{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prÃ©nom</th>\n",
       "      <th>nom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KÃ©vin</td>\n",
       "      <td>Ferreira</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  prÃ©nom       nom\n",
       "0  KÃ©vin  Ferreira"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(data = {\"prÃ©nom\":[\"KÃ©vin\"], \"nom\":[\"Ferreira\"]})\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and manipulate data with the pandas library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What you will learn in this course ðŸ§ðŸ§\n",
    "\n",
    "In Data Science, one of the libraries to know is Pandas. This library will allow you to manipulate databases very easily. So we're going to learn to:\n",
    "\n",
    "* Read and write Excel & CSV files via Pandas\n",
    "* Create databases\n",
    "* Merging databases\n",
    "* Manage missing data\n",
    "* Manage categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Python libraries ##\n",
    "\n",
    "### What's a library ?\n",
    "\n",
    "Now that you have an idea of what object-oriented programming is, using libraries shouldn't seem too complex. Indeed, a library is a module in which there are several classes that you can use at your discretion.\n",
    "\n",
    "You have probably seen or heard of _pandas, numpy and scikit-learn._ These are three very popular libraries among data scientists, which provide classes that are toolboxes for data manipulation and machine learning.\n",
    "\n",
    "\n",
    "#### How to import a library ?\n",
    "\n",
    "\n",
    "```python\n",
    "import module_name\n",
    "```\n",
    "\n",
    "\n",
    "It's as simple as that to import a library. However, by doing this you have imported your entire library at once. Sometimes it is not useful or even counterproductive to do this because it will slow down your code considerably.\n",
    "\n",
    "As a result, you often decide to import only one class of the module. This is done in the following way:\n",
    "\n",
    "\n",
    "```python\n",
    "from module_name import class_name\n",
    "```\n",
    "\n",
    "\n",
    "#### How to use a library ?\n",
    "\n",
    "A library contains classes definitions (with their attributes and methods) that you can use in your own code. To declare an instance of a class from a library, you can proceed as follow :\n",
    "\n",
    "```python\n",
    "import library_name\n",
    "class_instance = library_name.class_name()\n",
    "```\n",
    "\n",
    "#### Read the documentation !\n",
    "\n",
    "One last thing to understand: there are a lot of different libraries and they don't work the same way. You will have to refer to the documentation of the library in question for more information. In the course of the program, we will see a lot of different libraries so that you can become familiar with the concept. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data structures in Pandas\n",
    "\n",
    "We have already seen a number of data types in Python. With Pandas, we are introducing two new data structures that need to be understood in order to move forward."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas and discover the classes\n",
    "\n",
    "Before we begin, let's not forget that for all the operations we show in this course, we have imported the Pandas library as follows. The instruction as allows to create an alias: in the following we will refer to the library with `pd`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series class\n",
    "A DataFrame that has only one dimension (one column) is a Series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For information on how to use a method, use the \"?\"\n",
    "# Class Series : same as a column in Excel/SQL\n",
    "pd.Series?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of the Series class and initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# An instance of the Series class is created and initialized with a list of values.\n",
    "data1 = pd.Series(data= [1.2, 3.4, 4.7, 6.7], name=\"values\")\n",
    "print(data1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### \"index\" attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The series have an index as attribute\n",
    "print(data1.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Accessing an item in the series via the index: similar operation to lists\n",
    "print(data1[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iterate on a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Iterate over the values of a series\n",
    "print('Directly iterate over the values')\n",
    "for values in data1:\n",
    "    print(values)\n",
    "print()\n",
    "    \n",
    "# It's also possible to use the series' index to iterate\n",
    "print(\"Same but we use the index :\")\n",
    "for i in data1.index:\n",
    "    print(\"index : {}, valeur: {}\".format(i, data1[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The DataFrame class\n",
    "\n",
    "A DataFrame is a succession of Series. It is a two-dimensional object with rows and columns. One can also think of a DataFrame as an excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A DataFrame is composed of several columns:\n",
    "pd.DataFrame?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Declare an instance of the DataFrame class and initialize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We create an instance of the DataFrame class and initialize it with the values\n",
    "data_dict = {\n",
    "    'name': ['Agnes', 'Sidi', 'Thibault', 'Samia', 'Henry', 'Georges'],\n",
    "    'age': [28, 37, 43, 33, 29, 57],\n",
    "    'job': ['web analyst', 'sales director', 'web analyst', 'sales director', \n",
    "                   'web analyst', 'developer']\n",
    "            }\n",
    "\n",
    "data2 = pd.DataFrame(data_dict)\n",
    "display(data2)  # Equivalent to print() with HTML rendering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we have buildta DataFrame composed of six lines and three columns _name_, _age_ and _job_. A lot of different operations/transformations can be done on Dataframes, we will describe the main ones later in the course."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Attributes \"index\", \"columns\", \"shape\", \"values\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Like Series, DataFrame has an 'index'  attribute :\n",
    "print(data2.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 'columns' attribute is used to retrieve the list of column names:\n",
    "print(data2.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The shape attribute returns the number of rows and columns as a tuple:\n",
    "print(data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The 'values' attribute allows to retrieve the values stored in the DataFrame in numpy.array format:\n",
    "print(data2.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View a preview of the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See an overview of the first 5 lines of the DataFrame\n",
    "data2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# See an overview of the last 5 lines of the DataFrame\n",
    "data2.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select one column\n",
    "display(data2['name'])\n",
    "print()\n",
    "\n",
    "# Select multiple columns\n",
    "col_list = ['name','job']\n",
    "display(data2[col_list])\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select sub-part of the DataFrame with slices\n",
    "# Select the first three lines of the DataFrame\n",
    "print(\"first three lines of the DataFrame, with every columns:\")\n",
    "display(data2.loc[0:2,:])\n",
    "print()\n",
    "\n",
    "# Select first three lines of the 'age' column\n",
    "print(\"three first lines of the 'age' column:\")\n",
    "display(data2.loc[0:2,'age'])\n",
    "print()\n",
    "\n",
    "# Select the fourth line of 'age' and 'job'\n",
    "print(\"fourth line of 'age' and 'job' columns:\")\n",
    "display(data2.loc[3,['age', 'job']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use iloc to access the columns via their position:\n",
    "display(data2.iloc[:,2])\n",
    "\n",
    "# With iloc, we can also use negative clues:\n",
    "display(data2.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use masks to select rows according to a certain condition:\n",
    "mask = data2['age'] > 30\n",
    "display(data2.loc[mask,['age','job']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read a data file\n",
    "If you are working on J.U.L.I.E. upload this file to your workspace : M02/D01/01-Exercices/src/chipotle.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the file with read_csv()\n",
    "dataset = pd.read_csv('src/chipotle.csv')\n",
    "display(dataset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are a lot of arguments that can be passed to read_csv() to improve the reading of the file\n",
    "pd.read_csv?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In our file, the first column contains the index. Let's use the argument \"index_col\" to specify it\n",
    "dataset = pd.read_csv('src/chipotle.csv', index_col=0)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Read others files types\n",
    "\n",
    "Pandas can handle other file types than csv. It will simply be enough to use the same logic with the right method. So here is a summary table of the different types of files you can read with Pandas :\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>File type</strong></td>\n",
    "    <td><strong>Method</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-csv-table\">read_csv()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"http://www.json.org/\">JSON</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-json-reader\" >read_json()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/HTML\">HTML</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-read-html\" >read_html()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Local clipboard</td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-clipboard\" >read_clipboard()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/Microsoft_Excel\">MS Excel</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a\n",
    "        href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel-reader\" >read_excel()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://support.hdfgroup.org/HDF5/whatishdf5.html\" >HDF5 Format</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5\" >read_hdf()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://github.com/wesm/feather\">Feather Format</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-feather\" >read_feather()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://parquet.apache.org/\">Parquet Format</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-parquet\" >read_parquet()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"http://msgpack.org/index.html\">Msgpack</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-msgpack\" >read_msgpack()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/Stata\">Stata</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-stata-reader\" >read_stata()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/SAS_(software)\">SAS</a></td>\n",
    "    <td>\n",
    "      <a\n",
    "        href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-sas-reader\" >read_sas()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://docs.python.org/3/library/pickle.html\" >Python Pickle Format</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-pickle\" >read_pickle()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-sql\" >read_sql()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/BigQuery\">Google Big Query</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-bigquery\" >read_gbq()</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n",
    "\n",
    "\n",
    "You should be able to find what you are looking for in all the file types offered.\n",
    "\n",
    "\n",
    "### Exporting a file\n",
    "\n",
    "Once you know how to import a file, it is very simple to be able to export because the logic is similar. For example, we will create a variable that we will export in CSV :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({\"first_name\":[\"Lucien\", \"Jocelyne\", \"Brigitte\"], \"age\":[29, 43, 32]})\n",
    "data.to_csv(\"data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we created a DataFrame that we called _data_ and then we exported it in csv in the Download folder of our machine. By the way, we called the file \"data.csv\" specifying the path at the same time.\n",
    "\n",
    "In the same way as for the import, you can export in several types of files, here are the main ones :\n",
    "\n",
    "\n",
    "<table>\n",
    "  <tr>\n",
    "    <td><strong>File</strong></td>\n",
    "    <td><strong>Method</strong></td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/Comma-separated_values\">CSV</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-store-in-csv\" >to_csv</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"http://www.json.org/\">JSON</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-json-writer\" >to_json</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/HTML\">HTML</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-html\" >to_html</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>Local clipboard</td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-clipboard\" >to_clipboard</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/Microsoft_Excel\">MS Excel</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-excel-writer\" >to_excel</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://support.hdfgroup.org/HDF5/whatishdf5.html\" >HDF5 Format</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-hdf5\" >to_hdf</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://github.com/wesm/feather\">Feather Format</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-feather\" >to_feather</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://parquet.apache.org/\">Parquet Format</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-parquet\" >to_parquet</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"http://msgpack.org/index.html\">Msgpack</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-msgpack\" >to_msgpack</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/Stata\">Stata</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-stata-writer\" >to_stata</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://docs.python.org/3/library/pickle.html\" >Python Pickle Format</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-pickle\" >to_pickle</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td><a href=\"https://en.wikipedia.org/wiki/SQL\">SQL</a></td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-sql\" >to_sql</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "  <tr>\n",
    "    <td>\n",
    "      <a href=\"https://en.wikipedia.org/wiki/BigQuery\">Google Big Query</a>\n",
    "    </td>\n",
    "    <td>\n",
    "      <a href=\"http://pandas.pydata.org/pandas-docs/stable/io.html#io-bigquery\" >to_gbq</a>\n",
    "    </td>\n",
    "  </tr>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulate datas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new column to the DataFrame\n",
    "data2['gender'] = ['F', 'M', 'M', 'F', 'M', 'M']\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add new row at the end of the DataFrame\n",
    "new_row = {\n",
    "    'name': 'JosÃ©phine',\n",
    "    'age': 43,\n",
    "    'job': 'developer',\n",
    "    'gender': 'F'\n",
    "          }\n",
    "\n",
    "data2 = data2.append(new_row, ignore_index=True)\n",
    "\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lambda and apply functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column with values that are calculated according to another column: apply/lambda functions\n",
    "\n",
    "# New column containing the square of the age\n",
    "data2['age_squared'] = data2['age'].apply(lambda x : x**2)\n",
    "\n",
    "# New column containing: age if age > 30, 0 otherwise\n",
    "data2['age_changed'] = data2['age'].apply(lambda x : x if x > 30 else 0)\n",
    "\n",
    "# New column indicating that the person is NOT a web analyst\n",
    "data2['not_web_analyst'] = data2['job'].apply(lambda x : x != 'web analyst')\n",
    "\n",
    "display(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change the structure of the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.groupby?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Aggregate lines with groupby:\n",
    "\n",
    "# Group by 'job' and then calculate the average value of the other columns\n",
    "display(data2.groupby('job').mean())\n",
    "\n",
    "# Group by 'job' then calculate the average value of the 'age' column.\n",
    "display(data2.groupby('job')['age'].mean())\n",
    "\n",
    "# Group by 'job' then 'gender' and calculate the median value of the other columns.\n",
    "display(data2.groupby(['job','gender']).median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2.pivot_table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Rearrange rows and columns with pivot_table :\n",
    "\n",
    "# DataFrame with : \n",
    "# - as many rows as there are 'jobs'\n",
    "# - as many columns as there is gender\n",
    "# - the values are the average of 'age'\n",
    "display(data2.pivot_table(index='job', columns='gender', values='age', aggfunc='mean'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will manipulate the following databases:\n",
    "data_sales1 = {\n",
    "    'sales_id' : ['001','002','003','004'], \n",
    "    'people_id' : [1, 4, 2, 1], \n",
    "    'product_id' : ['X789', 'X999', 'X789', 'X990']\n",
    "              }\n",
    "\n",
    "data_sales2 = {\n",
    "    'sales_id' : ['005', '006', '007'],\n",
    "    'people_id' : [0, 3, 2],\n",
    "    'product_id' : ['X789', 'X999', 'X789'] \n",
    "               }\n",
    "\n",
    "data_products = {\n",
    "    'product_id' : ['X789', 'X999', 'X990'],\n",
    "    'product_desc' : ['Apple', 'Banana', 'Orange']\n",
    "                } \n",
    "\n",
    "data_people = {\n",
    "    'id' : [0, 1, 2, 3, 5],\n",
    "    'name' : ['Paul','Perrine','Moussa','Michel', 'Anne'],\n",
    "    'age' : [None, 67, 24, 76, 47]\n",
    "              }\n",
    "\n",
    "df_sales1 = pd.DataFrame(data_sales1)\n",
    "df_sales2 = pd.DataFrame(data_sales2)\n",
    "df_products = pd.DataFrame(data_products)\n",
    "df_people = pd.DataFrame(data_people)\n",
    "\n",
    "display(df_sales1)\n",
    "display(df_sales2)\n",
    "display(df_products)\n",
    "display(df_people)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Concatenate lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the lines of df_sales2 after df_sales1 :\n",
    "df_sales = pd.concat([df_sales1,df_sales2], ignore_index=True)\n",
    "display(df_sales)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make join operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join columns from sales and product\n",
    "# Simple case: All product_id in df_sales are present in df_product and vice versa\n",
    "\n",
    "df_sales_product = df_sales.merge(df_products,on='product_id')\n",
    "display(df_sales_product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join columns from people with sales_product\n",
    "# Warning 1: the columns containing the join id do not have the same name\n",
    "# Warning 2: the people_id 4 present in df_sales_product does not exist in df_people!\n",
    "# People_id 5 is in df_people but not in df_sales_product\n",
    "# We have to make a choice: what to do with the missing ids?\n",
    "\n",
    "# Inner join: we only keep the ids that are in both tables\n",
    "df_final1 = df_sales_product.merge(df_people, left_on='people_id', right_on='id', how='inner')\n",
    "\n",
    "# Outer join: we keep all the ids we find in both tables and fill the missing values in with NaN\n",
    "df_final2 = df_sales_product.merge(df_people, left_on='people_id', right_on='id', how='outer')\n",
    "\n",
    "# Left join: we keep all the ids from the left table and fill the mising values with NaN\n",
    "df_final3 = df_sales_product.merge(df_people, left_on='people_id', right_on='id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_final3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ressources ðŸ“šðŸ“š\n",
    "\n",
    "How to learn Pandas - [https://bit.ly/2CDDc4Z](https://bit.ly/2CDDc4Z)\n",
    "\n",
    "Missing values - [https://bit.ly/2yK66w2](https://bit.ly/2yK66w2)\n",
    "\n",
    "Interpolation - [https://bit.ly/2RW2y2u](https://bit.ly/2RW2y2u)\n",
    "\n",
    "Categorical variables - [https://bit.ly/2CK313e](https://bit.ly/2CK313e)\n",
    "\n",
    "Dummy variable trap - [https://bit.ly/2ElOEnj](https://bit.ly/2ElOEnj)\n",
    "\n",
    "Group By - [https://bit.ly/2EpF5DW](https://bit.ly/2EpF5DW)\n",
    "\n",
    "Handling multiple databases - [https://bit.ly/2PAUkLD](https://bit.ly/2PAUkLD)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "fbc4d3870518eee81184ced0d2279c769a0eca59aab465c4e7ec13e5e6c47a3e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
